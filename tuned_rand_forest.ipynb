{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb0630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba10b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_14584\\3458455485.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  def preprocess_data(file_path='E:\\AIML Tasks\\Titanic-Dataset.csv'):\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_14584\\3458455485.py:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_search = re.search(' ([A-Za-z]+)\\.', name)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(file_path='E:\\AIML Tasks\\Titanic-Dataset.csv'):\n",
    "    \"\"\"Loads and fully preprocesses the Titanic dataset.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    #  Step 1: Handle Missing Values (Part 1) & Drop Columns \n",
    "    embarked_mode = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "    df = df.drop(columns=['Cabin', 'PassengerId', 'Ticket'])\n",
    "\n",
    "    #  Step 2: Feature Engineering \n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "\n",
    "    df['Title'] = df['Name'].apply(get_title)\n",
    "    common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n",
    "    df['Title'] = df['Title'].apply(lambda x: x if x in common_titles else 'Other')\n",
    "    df = df.drop(columns=['Name'])\n",
    "\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df = df.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "    #  Step 3: Categorical Feature Encoding \n",
    "    le = LabelEncoder()\n",
    "    df['Sex'] = le.fit_transform(df['Sex']) # male=1, female=0\n",
    "    df = pd.get_dummies(df, columns=['Embarked', 'Title'], drop_first=True)\n",
    "\n",
    "    #  Step 4: Define X and y, then Split \n",
    "    y = df['Survived']\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #  Step 5: Post-Split Imputation (Age) \n",
    "    age_imputer = SimpleImputer(strategy='median')\n",
    "    X_train.loc[:, 'Age'] = age_imputer.fit_transform(X_train[['Age']])\n",
    "    X_test.loc[:, 'Age'] = age_imputer.transform(X_test[['Age']])\n",
    "\n",
    "    #  Step 6: Post-Split Feature Scaling \n",
    "    cols_to_scale = ['Age', 'Fare', 'FamilySize']\n",
    "    scaler = StandardScaler()\n",
    "    X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "    X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8c7d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_14584\\3458455485.py:46: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.55466613 -0.55466613 -0.55466613  0.04009635  3.01390875  0.04009635\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.04009635  3.01390875 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  1.22962131 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613  1.82438379\n",
      "  1.82438379  0.63485883  0.04009635  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      "  1.22962131  0.04009635 -0.55466613  0.04009635  1.82438379 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  1.22962131  0.63485883  0.04009635  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613  0.63485883\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  2.41914627 -0.55466613\n",
      "  1.22962131  0.63485883  0.63485883 -0.55466613 -0.55466613  0.63485883\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  1.22962131  0.04009635\n",
      " -0.55466613  0.63485883  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  1.82438379 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  1.82438379\n",
      " -0.55466613 -0.55466613  0.63485883  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  3.01390875 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635  0.04009635  1.82438379\n",
      " -0.55466613  3.60867123 -0.55466613  0.63485883 -0.55466613  2.41914627\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635  0.04009635\n",
      "  0.63485883 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635  1.22962131 -0.55466613  0.04009635  2.41914627  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883 -0.55466613  1.22962131 -0.55466613  1.22962131  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.63485883  1.82438379 -0.55466613  5.39295867  0.63485883\n",
      "  0.04009635  0.04009635 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  3.01390875 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  2.41914627 -0.55466613\n",
      "  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627  0.04009635 -0.55466613 -0.55466613  0.63485883  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  2.41914627  0.63485883  0.04009635  0.63485883 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613  3.01390875 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613 -0.55466613  2.41914627\n",
      " -0.55466613  1.22962131 -0.55466613  0.04009635 -0.55466613  2.41914627\n",
      "  0.04009635  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  5.39295867 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  0.63485883  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  5.39295867  0.63485883  0.04009635  2.41914627\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883  2.41914627  2.41914627 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635  2.41914627\n",
      " -0.55466613  0.04009635  1.82438379 -0.55466613 -0.55466613  1.82438379\n",
      "  1.22962131 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613  1.22962131\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  1.22962131 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  3.01390875  0.04009635  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613  0.63485883  3.01390875  1.22962131 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  1.82438379 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  1.22962131 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.63485883 -0.55466613 -0.55466613  0.04009635\n",
      "  1.22962131 -0.55466613  2.41914627 -0.55466613 -0.55466613  1.22962131\n",
      " -0.55466613  0.63485883  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  3.60867123  5.39295867 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  1.82438379\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635  3.01390875\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  5.39295867  0.04009635  1.22962131  0.04009635\n",
      "  0.04009635  0.04009635 -0.55466613  2.41914627  0.04009635 -0.55466613\n",
      " -0.55466613  0.04009635  1.22962131  0.04009635  3.01390875  0.04009635\n",
      "  1.22962131 -0.55466613  0.63485883  5.39295867 -0.55466613  0.04009635\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  2.41914627 -0.55466613  0.04009635 -0.55466613\n",
      "  0.04009635 -0.55466613  3.60867123  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  1.22962131 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  1.22962131 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883  1.22962131\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  5.39295867 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  3.01390875 -0.55466613  1.22962131 -0.55466613\n",
      "  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  1.22962131 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131  0.04009635]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_14584\\3458455485.py:47: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.63485883 -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      "  1.82438379 -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613  2.41914627 -0.55466613 -0.55466613  2.41914627 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635  1.82438379 -0.55466613 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131  0.63485883  2.41914627  1.22962131\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883  0.04009635  0.63485883  1.82438379\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  2.41914627 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883  3.01390875 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883  1.82438379\n",
      "  1.22962131 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      "  2.41914627  0.63485883 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  3.01390875 -0.55466613  0.63485883]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Tuned Random Forest Model (GridSearchCV) ---\n",
      "Starting Hyperparameter Tuning...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "--- Hyperparameter Tuning Complete ---\n",
      "Best parameters found: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation accuracy: 0.8314\n",
      "\n",
      "--- Tuned Model Accuracy on Test Set ---\n",
      "Accuracy: 0.8380 (or 83.80%)\n",
      "\n",
      "--- Tuned Model Classification Report ---\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Did Not Survive (0)       0.85      0.89      0.87       105\n",
      "       Survived (1)       0.83      0.77      0.80        74\n",
      "\n",
      "           accuracy                           0.84       179\n",
      "          macro avg       0.84      0.83      0.83       179\n",
      "       weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessed data\n",
    "X_train, X_test, y_train, y_test = preprocess_data()\n",
    "\n",
    "print(\"--- Training Tuned Random Forest Model (GridSearchCV) ---\")\n",
    "    \n",
    "#  Defining the Parameter Grid \n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "#  Initializing GridSearchCV \n",
    "# We use n_jobs=1 to prevent potential errors in some environments\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1, # Set to 1 to avoid pickling errors\n",
    "    verbose=1 \n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#  Get Best Model \n",
    "print(\"\\n--- Hyperparameter Tuning Complete ---\")\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "#  Evaluate Best Model \n",
    "y_pred_tuned_rf = best_rf_model.predict(X_test)\n",
    "    \n",
    "accuracy_tuned_rf = accuracy_score(y_test, y_pred_tuned_rf)\n",
    "print(f\"\\n--- Tuned Model Accuracy on Test Set ---\")\n",
    "print(f\"Accuracy: {accuracy_tuned_rf:.4f} (or {accuracy_tuned_rf*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n--- Tuned Model Classification Report ---\")\n",
    "report_tuned_rf = classification_report(y_test, y_pred_tuned_rf, target_names=['Did Not Survive (0)', 'Survived (1)'])\n",
    "print(report_tuned_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca99ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "File saved: best_rf_model.joblib\n"
     ]
    }
   ],
   "source": [
    "#  Save Model \n",
    "print(\"Saving model...\")\n",
    "\n",
    "# Save the Tuned Random Forest model\n",
    "joblib.dump(best_rf_model, 'best_rf_model.joblib')\n",
    "\n",
    "print(\"File saved: best_rf_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
