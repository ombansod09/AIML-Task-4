{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1b5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dfd2b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_32484\\438311710.py:1: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  def preprocess_data(file_path='E:\\AIML Tasks\\Titanic-Dataset.csv'):\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_32484\\438311710.py:13: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  title_search = re.search(' ([A-Za-z]+)\\.', name)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(file_path='E:\\AIML Tasks\\Titanic-Dataset.csv'):\n",
    "    \"\"\"Loads and fully preprocesses the Titanic dataset.\"\"\"\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    #  Step 1: Handle Missing Values & Drop Columns \n",
    "    embarked_mode = df['Embarked'].mode()[0]\n",
    "    df['Embarked'] = df['Embarked'].fillna(embarked_mode)\n",
    "    df = df.drop(columns=['Cabin', 'PassengerId', 'Ticket'])\n",
    "\n",
    "    #  Step 2: Feature Engineering \n",
    "    def get_title(name):\n",
    "        title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "        if title_search:\n",
    "            return title_search.group(1)\n",
    "        return \"\"\n",
    "\n",
    "    df['Title'] = df['Name'].apply(get_title)\n",
    "    common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n",
    "    df['Title'] = df['Title'].apply(lambda x: x if x in common_titles else 'Other')\n",
    "    df = df.drop(columns=['Name'])\n",
    "\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df = df.drop(columns=['SibSp', 'Parch'])\n",
    "\n",
    "    #  Step 3: Categorical Feature Encoding \n",
    "    le = LabelEncoder()\n",
    "    df['Sex'] = le.fit_transform(df['Sex']) # male=1, female=0\n",
    "    df = pd.get_dummies(df, columns=['Embarked', 'Title'], drop_first=True)\n",
    "\n",
    "    #  Step 4: Define X and y, then Split \n",
    "    y = df['Survived']\n",
    "    X = df.drop('Survived', axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    #  Step 5: Post-Split Imputation (Age) \n",
    "    age_imputer = SimpleImputer(strategy='median')\n",
    "    X_train.loc[:, 'Age'] = age_imputer.fit_transform(X_train[['Age']])\n",
    "    X_test.loc[:, 'Age'] = age_imputer.transform(X_test[['Age']])\n",
    "\n",
    "    #  Step 6: Post-Split Feature Scaling \n",
    "    cols_to_scale = ['Age', 'Fare', 'FamilySize']\n",
    "    scaler = StandardScaler()\n",
    "    X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "    X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fc7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training Default Random Forest Model ---\n",
      "--- Model Accuracy ---\n",
      "Accuracy: 0.8268 (or 82.68%)\n",
      "\n",
      "--- Classification Report ---\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Did Not Survive (0)       0.84      0.87      0.85       105\n",
      "       Survived (1)       0.80      0.77      0.79        74\n",
      "\n",
      "           accuracy                           0.83       179\n",
      "          macro avg       0.82      0.82      0.82       179\n",
      "       weighted avg       0.83      0.83      0.83       179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_32484\\438311710.py:46: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.55466613 -0.55466613 -0.55466613  0.04009635  3.01390875  0.04009635\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.04009635  3.01390875 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  1.22962131 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613  1.82438379\n",
      "  1.82438379  0.63485883  0.04009635  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      "  1.22962131  0.04009635 -0.55466613  0.04009635  1.82438379 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  1.22962131  0.63485883  0.04009635  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613  0.63485883\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  2.41914627 -0.55466613\n",
      "  1.22962131  0.63485883  0.63485883 -0.55466613 -0.55466613  0.63485883\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  1.22962131  0.04009635\n",
      " -0.55466613  0.63485883  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  1.82438379 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  1.82438379\n",
      " -0.55466613 -0.55466613  0.63485883  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  3.01390875 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635  0.04009635  1.82438379\n",
      " -0.55466613  3.60867123 -0.55466613  0.63485883 -0.55466613  2.41914627\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635  0.04009635\n",
      "  0.63485883 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635  1.22962131 -0.55466613  0.04009635  2.41914627  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883 -0.55466613  1.22962131 -0.55466613  1.22962131  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.63485883  1.82438379 -0.55466613  5.39295867  0.63485883\n",
      "  0.04009635  0.04009635 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  3.01390875 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  2.41914627 -0.55466613\n",
      "  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627  0.04009635 -0.55466613 -0.55466613  0.63485883  0.63485883\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  2.41914627  0.63485883  0.04009635  0.63485883 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613  3.01390875 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613 -0.55466613  2.41914627\n",
      " -0.55466613  1.22962131 -0.55466613  0.04009635 -0.55466613  2.41914627\n",
      "  0.04009635  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  5.39295867 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  0.63485883  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  5.39295867  0.63485883  0.04009635  2.41914627\n",
      " -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883  2.41914627  2.41914627 -0.55466613\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635  2.41914627\n",
      " -0.55466613  0.04009635  1.82438379 -0.55466613 -0.55466613  1.82438379\n",
      "  1.22962131 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613  1.22962131\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  1.22962131 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613  3.01390875  0.04009635  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613  0.63485883  3.01390875  1.22962131 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613  1.82438379 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  1.22962131 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  0.63485883 -0.55466613 -0.55466613  0.04009635\n",
      "  1.22962131 -0.55466613  2.41914627 -0.55466613 -0.55466613  1.22962131\n",
      " -0.55466613  0.63485883  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  3.60867123  5.39295867 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  1.82438379\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.04009635  3.01390875\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  5.39295867  0.04009635  1.22962131  0.04009635\n",
      "  0.04009635  0.04009635 -0.55466613  2.41914627  0.04009635 -0.55466613\n",
      " -0.55466613  0.04009635  1.22962131  0.04009635  3.01390875  0.04009635\n",
      "  1.22962131 -0.55466613  0.63485883  5.39295867 -0.55466613  0.04009635\n",
      "  0.63485883 -0.55466613 -0.55466613 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613  2.41914627 -0.55466613  0.04009635 -0.55466613\n",
      "  0.04009635 -0.55466613  3.60867123  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  1.22962131 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  1.22962131 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883  1.22962131\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  5.39295867 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  3.01390875 -0.55466613  1.22962131 -0.55466613\n",
      "  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.63485883 -0.55466613 -0.55466613 -0.55466613\n",
      "  2.41914627 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613  1.22962131 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635  3.60867123 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131  0.04009635]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_train.loc[:, cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
      "C:\\Users\\Om\\AppData\\Local\\Temp\\ipykernel_32484\\438311710.py:47: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.63485883 -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613  0.63485883 -0.55466613  0.63485883  0.04009635 -0.55466613\n",
      "  1.82438379 -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613  2.41914627 -0.55466613 -0.55466613  2.41914627 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635  1.82438379 -0.55466613 -0.55466613\n",
      " -0.55466613  0.63485883  1.22962131  0.63485883  2.41914627  1.22962131\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.63485883  0.04009635  0.63485883  1.82438379\n",
      " -0.55466613  0.63485883 -0.55466613  0.04009635 -0.55466613  0.63485883\n",
      " -0.55466613  0.63485883  2.41914627 -0.55466613  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.63485883  3.01390875 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613 -0.55466613 -0.55466613 -0.55466613\n",
      "  0.04009635 -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613 -0.55466613  0.63485883  1.82438379\n",
      "  1.22962131 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  0.04009635  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      "  2.41914627  0.63485883 -0.55466613 -0.55466613  0.04009635 -0.55466613\n",
      " -0.55466613 -0.55466613 -0.55466613  0.04009635 -0.55466613 -0.55466613\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613 -0.55466613\n",
      " -0.55466613  0.04009635 -0.55466613  0.04009635 -0.55466613  0.04009635\n",
      " -0.55466613 -0.55466613  0.04009635  0.63485883 -0.55466613  0.63485883\n",
      " -0.55466613 -0.55466613  3.01390875 -0.55466613  0.63485883]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X_test.loc[:, cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocessed data\n",
    "X_train, X_test, y_train, y_test = preprocess_data()\n",
    "\n",
    "print(\"--- Training Default Random Forest Model ---\")\n",
    "    \n",
    "# Initializing the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate \n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"--- Model Accuracy ---\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f} (or {accuracy_rf*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n--- Classification Report ---\")\n",
    "report_rf = classification_report(y_test, y_pred_rf, target_names=['Did Not Survive (0)', 'Survived (1)'])\n",
    "print(report_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7008cee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "File saved: rf_model.joblib\n"
     ]
    }
   ],
   "source": [
    "#  Save Model \n",
    "print(\"Saving model...\")\n",
    "\n",
    "# Save the Default Random Forest model\n",
    "joblib.dump(rf_model, 'rf_model.joblib')\n",
    "\n",
    "print(\"File saved: rf_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
